Generative AI
=============

Data + Algorithms = AI Machines
Large size and High diversity dataset would be ideal to use for ML

Real-world Examples:
--------------------
- Apple Siri
- Netflix Recommendation
- Autonomous Vehicles (Tesla, Waymo)
- Chatbots

Generative AI (Gen-AI)
======================
Generative AI is a powerful subset of AI focused on creating new content, including:
- Text
- Images
- Audio
- Videos

Machine Learning (ML)
=====================
Machine Learning is a branch of computer science that uses data and algorithms to enable AI to imitate human learning, gradually improving accuracy through experience.

Definition by Tom Mitchell:
----------------------------
"A subset of AI algorithms that learn without being explicitly programmed with rules. They use data to learn and match patterns."

Types of Machine Learning:
---------------------------
- Supervised Learning - models are trained on labelled data
- Unsupervised Learning - models find patterns in unlabeled data
- Reinforcement Learning - agents learn by interacting with their environment and receiving rewards or penalties

@ A regression model predicts a numeric value. For example, a weather model that predicts the amount of rain, in inches or millimetres, is a regression model.
@ Classification models predict the likelihood that something belongs to a category. Unlike regression models, whose output is a number, classification models output a value that states whether or not something belongs to a particular category. For example, classification models are used to predict if an email is spam or if a photo contains a cat.

Classification models are divided into two groups: binary classification and multiclass classification. Binary classification models output a value from a class that contains only two values. Multiclass classification models output a value from a class that contains more than two values.

# Once we're satisfied with the results from evaluating the model, we can use the model to make predictions, called inferences, on unlabeled examples.

Decision Forest
Decision forests are most effective when you have a tabular dataset (data you might represent in a spreadsheet, csv file, or database table). Tabular data is one of the most common data formats, and decision forests should be your “go-to” solution for modeling it. Decision forests perform best when lots of data is available.



Deep Learning
=============
Deep learning teaches computers to process data in a way inspired by the human brain, utilizing artificial neurons. Deep learning models are computer files that data scientists have trained to perform tasks using an algorithm or a predefined set of steps. Businesses use deep learning models to analyze data and make predictions in various applications.

Uses of Deep Learning
---------------------
- Computer Vision
- Natural Language Processing
- Recommendation Engines
- Speech Recognition

Key Differences:
----------------
Black and White Images:
- Definition: Also known as binary images, containing only black and white.
- Color Depth: Each pixel is either black (0) or white (1).
- Usage: Ideal for simple graphics, text, or high-contrast images.

Grayscale Images:
- Definition: Contains shades of grey from black to white.
- Colour Depth: Typically uses 8 bits per pixel for 256 different shades.
- Usage: Common in photography, medical imaging, and applications requiring detailed brightness levels.

-> Grayscale images are most commonly utilised.

Deep Learning Architectures:
----------------------------
- ANN (Artificial Neural Network): Used for structured data.
- CNN (Convolutional Neural Network): Used for images and videos.
- RNN (Recurrent Neural Network): Designed for sequential data.

Object Detection vs. Object Recognition:
----------------------------------------
- Object Detection: Identifies and localizes objects using bounding boxes.
- Object Recognition: Categorizes objects without precise localization.

Feed-Forward Neural Network (FNN)
=================================
A type of neural network where connections do not form cycles. Information flows in one direction: from input to output.

Structure:
- Input Layer: Receives input data, with each neuron representing a feature.
- Hidden Layers: Learn complex patterns from the data.
- Output Layer: Provides final outputs based on the classification or regression problem.

Backpropagation
===============
An iterative algorithm that minimizes the cost function by adjusting weights and biases.  During each epoch, the model learns by adapting these parameters to reduce loss.

Activation Function: Rectified Linear Unit (ReLU)
-------------------------------------------------
The ReLU function outputs the input directly if positive; otherwise, it outputs zero. It’s widely used due to its effectiveness in training and performance.

Example Code for Neural Network:
--------------------------------
model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))  # Input + Hidden Layer
model.add(Dense(16, activation="relu"))  # Second Hidden Layer

Adam Optimizer
==============
The Adaptive Moment Estimation (Adam) algorithm is efficient for optimization in gradient descent, particularly with large datasets.

Epoch
=====
An epoch refers to one complete pass through the entire training dataset. During an epoch, every training sample in the dataset is processed by the model, and its weights and biases are updated by the computed loss or error.

Real-world Applications of CNN:
-------------------------------
- Object Detection
- Optical Character Recognition (OCR)
- Facial Recognition
- Self-Driving Cars
- Healthcare
- Agriculture
- Security

Layers of CNN:
--------------
- Convolution: Extracts features from images.
- Max Pooling: Reduces resolution while retaining important features.
- Flattening: Converts the pooled feature map into a flat vector.
- Full Connection: Links the flattened vector to the output.

Convolution and Padding
=======================
- Convolution: A mathematical operation that extracts features by learning image characteristics using small data squares.
- Padding: Adds zeros to the input matrix to maintain spatial dimensions after filtering.

Pooling Layers:
---------------
- Max Pooling: Selects the maximum element in the feature map region.
- Average Pooling: Computes the average of the elements in the feature map region.

Natural Language Processing (NLP)
=================================
NLP gives computers the ability to interpret and understand human language.

Challenges of NLP:
------------------
- Ambiguity
- Contextual Variability
- Slang
- Sarcasm

NLP Pipeline Steps:
-------------------
1. Data Acquisition
2. Text Preprocessing
3. Feature Engineering
4. Modelling and Evaluation
5. Deployment

Text Processing Techniques:
----------------------------
Basic Text Processing:
- HTML tag removal
- Handling emojis
- Basic spell checks
- Tokenization
- Stop word removal
- Stemming/Lemmatization
- Lowercasing

Advanced Text Processing:
- Parts of Speech Tagging
- Parsing
- Coreference Resolution

Stop Words:
-----------
Stop words are common words removed from text-processing tasks due to their insignificance. Examples include: "the", "and", "is", "a", "in".

Recurrent Neural Network (RNN)
==============================
An RNN processes sequential data inputs to produce specific sequential outputs.

Long Short-Term Memory (LSTM)
=============================
Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) designed to better capture long-term dependencies in sequential data. Traditional RNNs struggle with remembering information over long sequences due to issues like the vanishing gradient problem, but LSTMs address this with a unique architecture.

Limitations of RNN:
-------------------
- Exploding Gradient
- Vanishing Gradient
- Slow Training Time


Key-Concepts behind GenAI
1. GANs (Generative Adversarial Networks)
2. Transformers
3. VAEs (Variational Autoencoders)
4. Diffusion Models

Image Generation is a process of using deep learning algorithms such as VAEs, GANs, and, more recently, Stable Diffusion to create new images that are visually similar to real-world images. Image Generation can be used for data augmentation to improve the performance of machine learning models, as well as in creating art, generating product images, and more.
Example: MidJourney, DALL-E

Video Generation involves deep learning methods such as GANs and Video Diffusion to generate new videos by predicting frames based on previous frames. Video Generation can be often seen in use with Speech Generation. The models used for speech generation can be powered by Transformers. Speech Generation can be used in text-to-speech conversion, virtual assistants, and voice cloning. 
Example: DeepBrain and Synthesia

Encoder-Decoder Architecture
----------------------------
1. Encoder: The encoder is responsible for processing the input sequence (e.g., a sentence or a sequence of data) and converting it into a fixed-size representation. The key function of the encoder is to summarize the input sequence into a more abstract form. The output of the encoder is the hidden or context vector, which captures the essence of the entire input sequence.

2. Hidden Vector: The hidden vector (also called the context vector) is the condensed representation of the input sequence generated by the encoder. This vector holds the crucial information about the input sequence in a form that can be passed to the decoder.

3. Decoder: The decoder takes the hidden vector from the encoder and generates the output sequence step by step. The decoder typically works by predicting the next token in the sequence, and it continues doing so until it produces the entire output.

Workflow:
--------
- Encoder: Processes the input sequence and outputs the hidden vector.
- Hidden Vector: Contains the summarized representation of the input.
- Decoder: Uses the hidden vector to generate the output sequence (one token at a time or all at once, depending on the architecture).

Real-life application of Encoder-Decoder
- Google machine translation
- Speech Recognition
- Time Series Analysis


Generative Adversarial Networks (GANs)
====================================== 
Generative Adversarial Networks (GANs) are a class of machine learning models designed for generating new data that resembles a given dataset. GANs are made up of two neural networks, a discriminator and a generator. They use adversarial training to produce artificial data that is identical to actual data.
 
Key Components of GANs
----------------------
Generator (G):

- The generator’s role is to generate fake data (e.g., fake images, text, or sound) from random noise.
- It takes as input a random vector (usually sampled from a simple distribution like Gaussian noise) and tries to produce data that looks as close as possible to the real data.
- Over time, the generator learns to produce more realistic data through its interactions with the discriminator.

Discriminator (D):

- The discriminator’s job is to distinguish between real data (from the actual dataset) and fake data generated by the generator.
- It’s a binary classifier that outputs a probability indicating whether the input is real or fake.
- The goal of the discriminator is to get better at telling apart real data from the fake data generated by the generator.

* During generator training, gradients propagate through the discriminator network to the generator network (although the discriminator does not update its weights during generator training). So the weights in the discriminator network influence the updates to the generator network.

* A typical GAN alternates between training the discriminator and training the generator.

* While a GAN can use the same loss for both generator and discriminator training (or the same loss differing only in sign), it's not required. It's more common to use different losses for the discriminator and the generator.

@ Small Language Models (SLMs) focus on specialised tasks with less data. Retrieval-augmented generation (RAG) enhances these models by pulling in external information for more accurate results. AI Agents use generative AI to autonomously perform tasks such as writing or research. Together, they represent cutting-edge advancements in automation and creativity.

Data Augmentation
=================
Data augmentation is a process of generating new training data by applying various image transformations such as flipping, cropping, rotating, and colour jittering. The goal is to increase the diversity of training data and avoid overfitting, which can lead to better performance of machine learning models. Deep learning models rely on large volumes of diverse data to develop accurate predictions in various contexts. Data augmentation supplements the creation of data variations that can help a model improve the accuracy of its predictions. 


Transformers
============
came into existence in 2017
Transformers are a type of neural network architecture that transforms or changes an input sequence into an output sequence. They do this by learning context and tracking relationships between sequence components.
Transformer models fundamentally changed NLP technologies by enabling models to handle such long-range dependencies in text.

It uses a self-attention mechanism to capture relationships between different words (or tokens) in a sequence, regardless of their distance from each other, allowing the model to weigh the importance of each word when generating or processing text. Instead of processing data in order, the mechanism enables the model to look at different parts of the sequence all at once and determine which parts are most important. 


# Since the dataset is huge, we don't build the transformer model from scratch, as it will take months to train,

Benefits of Transformers:
- Enable large-scale models
- Enable faster customization
- Facilitate multi-modal AI systems
- AI research and industry innovation




df.sample(n): to return n random rows from the data











