{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Pre-trained Models\n",
    "\n",
    "In this notebook, we'll demonstrate transfer learning using pre-trained models for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Use a subset for faster training\n",
    "train_size = 5000\n",
    "test_size = 1000\n",
    "\n",
    "x_train_subset = x_train[:train_size]\n",
    "y_train_subset = y_train[:train_size]\n",
    "x_test_subset = x_test[:test_size]\n",
    "y_test_subset = y_test[:test_size]\n",
    "\n",
    "print(f\"Training samples: {x_train_subset.shape[0]}\")\n",
    "print(f\"Test samples: {x_test_subset.shape[0]}\")\n",
    "print(f\"Image shape: {x_train_subset.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for pre-trained models\n",
    "def preprocess_for_pretrained(x_data, target_size=(224, 224)):\n",
    "    \"\"\"Preprocess images for pre-trained models\"\"\"\n",
    "    # Resize images to target size\n",
    "    x_resized = tf.image.resize(x_data, target_size)\n",
    "    \n",
    "    # Convert to float32 and normalize\n",
    "    x_resized = tf.cast(x_resized, tf.float32)\n",
    "    \n",
    "    return x_resized\n",
    "\n",
    "# Resize images to 224x224 (standard input size for many pre-trained models)\n",
    "x_train_resized = preprocess_for_pretrained(x_train_subset)\n",
    "x_test_resized = preprocess_for_pretrained(x_test_subset)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = keras.utils.to_categorical(y_train_subset, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test_subset, 10)\n",
    "\n",
    "print(f\"Resized training shape: {x_train_resized.shape}\")\n",
    "print(f\"Resized test shape: {x_test_resized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize resized images\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    # Original image\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_train_subset[i])\n",
    "    plt.title(f'Original 32x32\\n{class_names[y_train_subset[i][0]]}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Resized image\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow(x_train_resized[i].numpy().astype('uint8'))\n",
    "    plt.title(f'Resized 224x224\\n{class_names[y_train_subset[i][0]]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(base_model_name='VGG16', num_classes=10, trainable=False):\n",
    "    \"\"\"Create transfer learning model\"\"\"\n",
    "    \n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == 'VGG16':\n",
    "        base_model = keras.applications.VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "        preprocess_func = keras.applications.vgg16.preprocess_input\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = keras.applications.ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "        preprocess_func = keras.applications.resnet50.preprocess_input\n",
    "    elif base_model_name == 'MobileNetV2':\n",
    "        base_model = keras.applications.MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "        preprocess_func = keras.applications.mobilenet_v2.preprocess_input\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    # Add custom classifier\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Lambda(preprocess_func),  # Preprocessing\n",
    "        base_model,\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create VGG16 transfer learning model\n",
    "vgg_model, vgg_base = create_transfer_model('VGG16', trainable=False)\n",
    "\n",
    "print(\"VGG16 Transfer Learning Model:\")\n",
    "vgg_model.summary()\n",
    "\n",
    "print(f\"\\nTotal parameters: {vgg_model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in vgg_model.trainable_weights]):,}\")\n",
    "print(f\"Non-trainable parameters: {sum([tf.size(w).numpy() for w in vgg_model.non_trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train VGG16 model\n",
    "vgg_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "print(\"Training VGG16 transfer learning model...\")\n",
    "vgg_history = vgg_model.fit(\n",
    "    x_train_resized, y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test_resized, y_test_cat),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"VGG16 training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple pre-trained models\n",
    "models_to_compare = ['VGG16', 'ResNet50', 'MobileNetV2']\n",
    "model_results = {}\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    # Create model\n",
    "    model, base_model = create_transfer_model(model_name, trainable=False)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train (fewer epochs for comparison)\n",
    "    history = model.fit(\n",
    "        x_train_resized, y_train_cat,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        validation_data=(x_test_resized, y_test_cat),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(x_test_resized, y_test_cat, verbose=0)\n",
    "    \n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'parameters': model.count_params()\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} - Test Accuracy: {test_acc:.4f}, Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\nAll models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "def compare_models(model_results):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Test accuracy comparison\n",
    "    models = list(model_results.keys())\n",
    "    accuracies = [model_results[model]['test_accuracy'] for model in models]\n",
    "    parameters = [model_results[model]['parameters'] for model in models]\n",
    "    \n",
    "    axes[0, 0].bar(models, accuracies, color=['blue', 'green', 'red'])\n",
    "    axes[0, 0].set_title('Test Accuracy Comparison')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        axes[0, 0].text(i, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "    \n",
    "    # Parameter count comparison\n",
    "    axes[0, 1].bar(models, [p/1e6 for p in parameters], color=['blue', 'green', 'red'])\n",
    "    axes[0, 1].set_title('Model Size Comparison')\n",
    "    axes[0, 1].set_ylabel('Parameters (Millions)')\n",
    "    \n",
    "    # Training history comparison\n",
    "    for model_name in models:\n",
    "        history = model_results[model_name]['history']\n",
    "        axes[1, 0].plot(history.history['accuracy'], label=f'{model_name} Train')\n",
    "        axes[1, 0].plot(history.history['val_accuracy'], label=f'{model_name} Val', linestyle='--')\n",
    "    \n",
    "    axes[1, 0].set_title('Training Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss comparison\n",
    "    for model_name in models:\n",
    "        history = model_results[model_name]['history']\n",
    "        axes[1, 1].plot(history.history['loss'], label=f'{model_name} Train')\n",
    "        axes[1, 1].plot(history.history['val_loss'], label=f'{model_name} Val', linestyle='--')\n",
    "    \n",
    "    axes[1, 1].set_title('Training Loss')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Model':<12} {'Accuracy':<10} {'Parameters':<12} {'Size (MB)':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for model_name in models:\n",
    "        acc = model_results[model_name]['test_accuracy']\n",
    "        params = model_results[model_name]['parameters']\n",
    "        size_mb = params * 4 / (1024 * 1024)  # Approximate size in MB\n",
    "        \n",
    "        print(f\"{model_name:<12} {acc:<10.4f} {params:<12,} {size_mb:<10.1f}\")\n",
    "\n",
    "compare_models(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the best performing model\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_accuracy'])\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "finetune_model, finetune_base = create_transfer_model(best_model_name, trainable=True)\n",
    "\n",
    "# Freeze early layers, unfreeze later layers\n",
    "finetune_base.trainable = True\n",
    "\n",
    "# Freeze the first 80% of layers\n",
    "freeze_layers = int(len(finetune_base.layers) * 0.8)\n",
    "for layer in finetune_base.layers[:freeze_layers]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Total layers in base model: {len(finetune_base.layers)}\")\n",
    "print(f\"Frozen layers: {freeze_layers}\")\n",
    "print(f\"Trainable layers: {len(finetune_base.layers) - freeze_layers}\")\n",
    "\n",
    "# Compile with lower learning rate for fine-tuning\n",
    "finetune_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),  # Lower learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\nFine-tuning model parameters:\")\n",
    "print(f\"Total: {finetune_model.count_params():,}\")\n",
    "print(f\"Trainable: {sum([tf.size(w).numpy() for w in finetune_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fine-tuned model\n",
    "print(\"Fine-tuning model...\")\n",
    "\n",
    "finetune_history = finetune_model.fit(\n",
    "    x_train_resized, y_train_cat,\n",
    "    batch_size=16,  # Smaller batch size for fine-tuning\n",
    "    epochs=10,\n",
    "    validation_data=(x_test_resized, y_test_cat),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "finetune_loss, finetune_acc = finetune_model.evaluate(x_test_resized, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nFine-tuned model performance:\")\n",
    "print(f\"Test Accuracy: {finetune_acc:.4f}\")\n",
    "print(f\"Original {best_model_name} Accuracy: {model_results[best_model_name]['test_accuracy']:.4f}\")\n",
    "print(f\"Improvement: {finetune_acc - model_results[best_model_name]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using pre-trained model\n",
    "def extract_features(model, x_data, layer_name=None):\n",
    "    \"\"\"Extract features from a specific layer\"\"\"\n",
    "    \n",
    "    if layer_name:\n",
    "        # Extract from specific layer\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=model.input,\n",
    "            outputs=model.get_layer(layer_name).output\n",
    "        )\n",
    "    else:\n",
    "        # Extract from second-to-last layer (before final classification)\n",
    "        feature_extractor = keras.Model(\n",
    "            inputs=model.input,\n",
    "            outputs=model.layers[-2].output\n",
    "        )\n",
    "    \n",
    "    features = feature_extractor.predict(x_data, verbose=0)\n",
    "    return features\n",
    "\n",
    "# Extract features from the best model\n",
    "best_model = model_results[best_model_name]['model']\n",
    "features = extract_features(best_model, x_test_resized[:100])  # Use first 100 test samples\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Feature vector length: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize features using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensionality first with PCA, then t-SNE\n",
    "pca = PCA(n_components=50)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "features_2d = tsne.fit_transform(features_pca)\n",
    "\n",
    "# Plot t-SNE visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get labels for first 100 test samples\n",
    "labels_subset = y_test_subset[:100].flatten()\n",
    "\n",
    "# Create scatter plot with different colors for each class\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    mask = labels_subset == i\n",
    "    plt.scatter(features_2d[mask, 0], features_2d[mask, 1], \n",
    "               c=[colors[i]], label=class_names[i], alpha=0.7, s=50)\n",
    "\n",
    "plt.title(f'Feature Visualization using t-SNE\\n({best_model_name} features)')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance ratio (first 10 components): {pca.explained_variance_ratio_[:10]}\")\n",
    "print(f\"Total variance explained by 50 components: {pca.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions from the best model\n",
    "best_model = model_results[best_model_name]['model']\n",
    "predictions = best_model.predict(x_test_resized, verbose=0)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = y_test_subset.flatten()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_classes, pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(f\"Classification Report - {best_model_name}:\")\n",
    "print(classification_report(true_classes, pred_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of correct and incorrect predictions\n",
    "def show_prediction_examples(x_test, y_true, predictions, class_names, num_examples=10):\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    confidences = np.max(predictions, axis=1)\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct_mask = (pred_classes == y_true)\n",
    "    incorrect_mask = ~correct_mask\n",
    "    \n",
    "    correct_indices = np.where(correct_mask)[0]\n",
    "    incorrect_indices = np.where(incorrect_mask)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_examples, figsize=(20, 8))\n",
    "    \n",
    "    # Show correct predictions\n",
    "    for i in range(min(num_examples, len(correct_indices))):\n",
    "        idx = correct_indices[i]\n",
    "        \n",
    "        # Convert from 224x224 back to displayable format\n",
    "        img = x_test[idx].numpy().astype('uint8')\n",
    "        \n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f'✓ {class_names[pred_classes[idx]]}\\n({confidences[idx]:.2f})', \n",
    "                           color='green', fontsize=10)\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Show incorrect predictions\n",
    "    for i in range(min(num_examples, len(incorrect_indices))):\n",
    "        idx = incorrect_indices[i]\n",
    "        \n",
    "        img = x_test[idx].numpy().astype('uint8')\n",
    "        \n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title(f'✗ Pred: {class_names[pred_classes[idx]]}\\nTrue: {class_names[y_true[idx]]}\\n({confidences[idx]:.2f})', \n",
    "                           color='red', fontsize=10)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(min(num_examples, len(correct_indices)), num_examples):\n",
    "        axes[0, i].axis('off')\n",
    "    for i in range(min(num_examples, len(incorrect_indices)), num_examples):\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Prediction Examples - {best_model_name}\\nTop: Correct Predictions, Bottom: Incorrect Predictions', \n",
    "                 fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_prediction_examples(x_test_resized, true_classes, predictions, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all experiments\n",
    "print(\"=\" * 80)\n",
    "print(\"TRANSFER LEARNING EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Dataset: CIFAR-10 (subset of {train_size} training, {test_size} test samples)\")\n",
    "print(f\"Input size: 224x224 (resized from 32x32)\")\n",
    "print(f\"Number of classes: 10\")\n",
    "print()\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "for model_name, results in model_results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Test Accuracy: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"  Parameters: {results['parameters']:,}\")\n",
    "    print(f\"  Model Size: ~{results['parameters'] * 4 / (1024*1024):.1f} MB\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Fine-tuned Accuracy: {finetune_acc:.4f}\")\n",
    "print(f\"Improvement from fine-tuning: {finetune_acc - model_results[best_model_name]['test_accuracy']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"- Transfer learning significantly reduces training time\")\n",
    "print(\"- Pre-trained features work well even for different domains\")\n",
    "print(\"- Fine-tuning can provide additional performance gains\")\n",
    "print(\"- Model size vs. accuracy trade-offs are important for deployment\")\n",
    "print(\"- Feature visualization helps understand model behavior\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}