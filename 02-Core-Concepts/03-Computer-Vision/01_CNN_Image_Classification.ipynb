{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification on CIFAR-10\n",
    "\n",
    "In this notebook, we'll build and train a CNN for image classification using the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Training set shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test set shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Pixel value range: {x_train.min()} - {x_train.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f'{class_names[y_train[i][0]]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from CIFAR-10 Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([class_names[i] for i in unique], counts)\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Samples per class:\")\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"{class_names[i]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Normalized pixel range: {x_train_norm.min()} - {x_train_norm.max()}\")\n",
    "print(f\"Original label shape: {y_train.shape}\")\n",
    "print(f\"Categorical label shape: {y_train_cat.shape}\")\n",
    "print(f\"Sample one-hot label: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    \"\"\"Create CNN model for CIFAR-10 classification\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # First Convolutional Block\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Classifier\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model architecture\n",
    "keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"- Early Stopping (patience=10)\")\n",
    "print(\"- Learning Rate Reduction (factor=0.5, patience=5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Fit the data generator\n",
    "datagen.fit(x_train_norm)\n",
    "\n",
    "# Visualize augmented images\n",
    "plt.figure(figsize=(15, 5))\n",
    "sample_image = x_train_norm[0:1]  # Take first image\n",
    "\n",
    "# Generate augmented versions\n",
    "augmented_images = []\n",
    "for batch in datagen.flow(sample_image, batch_size=1):\n",
    "    augmented_images.append(batch[0])\n",
    "    if len(augmented_images) >= 5:\n",
    "        break\n",
    "\n",
    "# Plot original and augmented images\n",
    "plt.subplot(1, 6, 1)\n",
    "plt.imshow(sample_image[0])\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, aug_img in enumerate(augmented_images):\n",
    "    plt.subplot(1, 6, i + 2)\n",
    "    plt.imshow(aug_img)\n",
    "    plt.title(f'Augmented {i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train_norm, y_train_cat, batch_size=32),\n",
    "    epochs=50,\n",
    "    validation_data=(x_test_norm, y_test_cat),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test_norm)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for i, acc in enumerate(class_accuracy):\n",
    "    print(f\"{class_names[i]}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correct and incorrect predictions\n",
    "def visualize_predictions(x_test, y_true, y_pred, class_names, num_images=20):\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Get random indices\n",
    "    indices = np.random.choice(len(x_test), num_images, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get prediction\n",
    "        pred_class = np.argmax(y_pred[idx])\n",
    "        true_class = y_true[idx]\n",
    "        confidence = y_pred[idx][pred_class]\n",
    "        \n",
    "        # Plot image\n",
    "        axes[i].imshow(x_test[idx])\n",
    "        \n",
    "        # Set title with color coding\n",
    "        if pred_class == true_class:\n",
    "            color = 'green'\n",
    "            title = f'✓ {class_names[pred_class]}\\n({confidence:.2f})'\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = f'✗ {class_names[pred_class]}\\nTrue: {class_names[true_class]}\\n({confidence:.2f})'\n",
    "        \n",
    "        axes[i].set_title(title, color=color, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions (Green=Correct, Red=Incorrect)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(x_test, y_true_classes, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize most confident correct and incorrect predictions\n",
    "def show_confident_predictions(x_test, y_true, y_pred, class_names):\n",
    "    # Get prediction confidences\n",
    "    pred_classes = np.argmax(y_pred, axis=1)\n",
    "    confidences = np.max(y_pred, axis=1)\n",
    "    \n",
    "    # Correct predictions\n",
    "    correct_mask = (pred_classes == y_true)\n",
    "    correct_indices = np.where(correct_mask)[0]\n",
    "    correct_confidences = confidences[correct_mask]\n",
    "    \n",
    "    # Incorrect predictions\n",
    "    incorrect_mask = (pred_classes != y_true)\n",
    "    incorrect_indices = np.where(incorrect_mask)[0]\n",
    "    incorrect_confidences = confidences[incorrect_mask]\n",
    "    \n",
    "    # Get most confident correct and incorrect\n",
    "    most_confident_correct = correct_indices[np.argmax(correct_confidences)]\n",
    "    most_confident_incorrect = incorrect_indices[np.argmax(incorrect_confidences)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Most confident correct\n",
    "    idx = most_confident_correct\n",
    "    axes[0].imshow(x_test[idx])\n",
    "    axes[0].set_title(f'Most Confident Correct\\nPredicted: {class_names[pred_classes[idx]]}\\nConfidence: {confidences[idx]:.4f}', \n",
    "                     color='green')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Most confident incorrect\n",
    "    idx = most_confident_incorrect\n",
    "    axes[1].imshow(x_test[idx])\n",
    "    axes[1].set_title(f'Most Confident Incorrect\\nPredicted: {class_names[pred_classes[idx]]}\\nTrue: {class_names[y_true[idx]]}\\nConfidence: {confidences[idx]:.4f}', \n",
    "                     color='red')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_confident_predictions(x_test, y_true_classes, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps from first convolutional layer\n",
    "def visualize_feature_maps(model, x_test, layer_name='conv2d'):\n",
    "    # Create a model that outputs feature maps\n",
    "    feature_model = keras.Model(inputs=model.input, \n",
    "                               outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    # Get feature maps for a sample image\n",
    "    sample_image = x_test[0:1]  # First test image\n",
    "    feature_maps = feature_model.predict(sample_image)\n",
    "    \n",
    "    # Plot original image and feature maps\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(sample_image[0])\n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Hide unused subplots in first row\n",
    "    for i in range(1, 8):\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Feature maps (first 8 channels)\n",
    "    for i in range(8):\n",
    "        axes[1, i].imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
    "        axes[1, i].set_title(f'Filter {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Feature Maps from {layer_name} Layer')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Feature maps shape: {feature_maps.shape}\")\n",
    "\n",
    "visualize_feature_maps(model, x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filters from first convolutional layer\n",
    "def visualize_filters(model, layer_name='conv2d'):\n",
    "    # Get the weights of the first convolutional layer\n",
    "    filters = model.get_layer(layer_name).get_weights()[0]\n",
    "    \n",
    "    # Normalize filters for visualization\n",
    "    f_min, f_max = filters.min(), filters.max()\n",
    "    filters = (filters - f_min) / (f_max - f_min)\n",
    "    \n",
    "    # Plot filters\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "    \n",
    "    for i in range(32):  # First 32 filters\n",
    "        row = i // 8\n",
    "        col = i % 8\n",
    "        \n",
    "        # Get filter\n",
    "        filter_img = filters[:, :, :, i]\n",
    "        \n",
    "        axes[row, col].imshow(filter_img)\n",
    "        axes[row, col].set_title(f'Filter {i+1}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Learned Filters from {layer_name} Layer')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Filter shape: {filters.shape}\")\n",
    "\n",
    "visualize_filters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance by class\n",
    "def analyze_class_performance(y_true, y_pred, class_names):\n",
    "    # Calculate per-class metrics\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for better visualization\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Class': class_names,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    print(\"Per-Class Performance:\")\n",
    "    print(df.round(4))\n",
    "    \n",
    "    # Visualize metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Precision\n",
    "    axes[0].bar(class_names, precision)\n",
    "    axes[0].set_title('Precision by Class')\n",
    "    axes[0].set_ylabel('Precision')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1].bar(class_names, recall)\n",
    "    axes[1].set_title('Recall by Class')\n",
    "    axes[1].set_ylabel('Recall')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1-Score\n",
    "    axes[2].bar(class_names, f1)\n",
    "    axes[2].set_title('F1-Score by Class')\n",
    "    axes[2].set_ylabel('F1-Score')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "performance_df = analyze_class_performance(y_true_classes, y_pred_classes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('cifar10_cnn_model.h5')\n",
    "print(\"Model saved as 'cifar10_cnn_model.h5'\")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Architecture: Custom CNN\")\n",
    "print(f\"Dataset: CIFAR-10\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Training Time: {len(history.history['loss'])} epochs\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}