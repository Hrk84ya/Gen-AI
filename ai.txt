Data+Algorithms=AI Machines


Real-world examples:
Apple Siri
Netflix Recommendation
Autonomous vehicles (Tesla, Waymo)
Chatbot

Gen-AI is a powerful subset of AI focused on creating new content, whether text, images, audio, or even videos.

Machine learning (ML) is a branch of computer science that focuses on using data and algorithms to enable AI to imitate how humans learn, gradually improving its accuracy. (Learn and improve from experience)

Definition of Machine Learning by Tom Mitchell:
A subset of AI algorithms which learn without being explicitly programmed with rules. Use data to learn and match patterns ~ Tom Mitchell.

Types of Machine Learning:
1. Supervised
2. Unsupervised
3. Reinforcement

Deep Learning: Deep learning is a method in artificial intelligence (AI) that teaches computers to process data in a way that is inspired by the human brain.
The functionality of artificial neurons is inspired by the human brain.

Difference Between Black&White and Grayscale Images

Black and White Images
Definition: Also known as binary images, these images contain only two colours: black and white.
Colour Depth: Each pixel in a black-and-white image can only be either black (0) or white (1), representing two levels of brightness.
Usage: Often used for simple graphics, text, or high-contrast images where colour is not necessary.

Grayscale Images
Definition: Grayscale images contain shades of grey, ranging from black to white.
Colour Depth: These images typically use 8 bits per pixel, allowing for 256 different shades of grey (from 0, which is black, to 255, which is white).
Usage: Grayscale images are common in photography, medical imaging, and other applications where a range of brightness levels is important for detail.


Deep Learning:
ANN - Artificial Neural Network (used for tabular data/structured data)
CNN - Convolutional Neural Network (used for images and videos)
RNN - Recurrent Neural Network ()

Difference between object detection and object recognition:
Object detection involves identifying and localising objects with bounding boxes and providing detailed information about their presence and location. Object recognition focuses on categorising objects without the need for precise localisation.

Feed-Forward Neural Network
A Feedforward Neural Network (FNN) is a type of artificial neural network where connections between the nodes do not form cycles. The network consists of an input layer, one or more hidden layers, and an output layer. Information flows in one direction—from input to output—hence the name “feedforward”.

Structure of a Feed-Forward Neural Network:
1. Input Layer: The input layer consists of neurons that receive the input data. Each neuron in the input layer represents a feature of the input data.
2. Hidden Layers: One or more hidden layers are placed between the input and output layers. These layers are responsible for learning the complex patterns in the data. Each neuron in a hidden layer applies a weighted sum of inputs followed by a non-linear activation function.
3. Output Layer: The output layer provides the final output of the network. The number of neurons in this layer corresponds to the number of classes in a classification problem or the number of outputs in a regression problem.


Backpropagation:
Backpropagation is an iterative algorithm that helps to minimise the cost function by determining which weights and biases should be adjusted. During every epoch, the model learns by adapting the weights and biases to minimise the loss by moving down toward the gradient of the error. Backpropagation is an effective algorithm used to train artificial neural networks, especially in feed-forward neural networks.

Rectified Linear Unit (ReLU)
The rectified linear activation function, or ReLU for short, is a piecewise linear function that will output the input directly if it is positive. Otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.

#Code for neural network
model.add(Dense(16, input_dim=X_train.shape[1],activation='relu)) # to create input layer + hidden layer
model.add(Dense(16,activation="relu")) # second hidden layer

Adam Optimizer (adam)
Adaptive Moment Estimation is an algorithm for optimisation techniques for gradient descent. The method is efficient when working with large problems involving a lot of data or parameters.

Epoch: An epoch is one complete pass through the entire training dataset. One pass means a complete forward and backward pass through the entire training dataset. 


Real-world Application of CNN:
1. Object Detection
2. OCR
3. Facial Recognition
4. Self-Driving Cars
5. Healthcare
6. Agriculture
7. Security

Layers of CNN:
1. Convolution
2. Max Pooling
3. Flattening
4. Full Connection

Convolution is the first layer to extract features from an input image. It preserves the relationship between pixels by learning image features using small squares of input data. It is a mathematical operation that takes two inputs, such as an image matrix and a filter or kernel.

Padding: Padding is the process of adding layers of zeros or other values outside the actual data in an input matrix. The primary purpose of padding is to preserve the spatial size of the input so that the output, after applying filters (kernels), remains the same size or adjusts it according to the desired output dimensions.

Pooling layer: It operates on each feature map independently. This reduces the resolution of the feature map by reducing the spatial dimensions (height and width of an image), effectively downsampling the feature map while retaining the most important features. This helps to decrease the computational load, prevent overfitting, and provide a form of translational invariance in the model.

Types of pooling layers: 
1. Max pooling: It is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after the max-pooling layer would be a feature map containing the most prominent features of the previous feature map. 

2. Average pooling: It computes the average of the elements present in the region of the feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch. 


Natural Language Processing
Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.

Challenges of NLP
1. Ambiguity
2. Contextual word
3. Slang
4. Sarcasm

NLP Pipeline Steps:
1. Data Acquisition
2. Text preprocessing
3. Feature engineering
4. Modelling and evaluation
5. Deployment


Text Processing
1. Basic Text Processing
2. Advance Text Processing

Basic Text Processing: HTML tag removal, Handling Emojis, Basic spell checks, Tokenisation, Stop word removal, Lemmatization, Lowercasing

Advanced Text Processing: Parts of speech tagging, Parsing, Coreference Resolution



